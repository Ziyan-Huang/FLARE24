# ğŸ” A 5.6M Parameter U-Net for Efficient Whole-body Tumor Segmentation (For MICCAI FLARE2024 challenge Task1)

## ğŸ†š Key Differences Between Our Method and nnUNetV2

| Configuration | Our Method ğŸš€ | nnUNetV2 ğŸ—¿ |
|---------------|--------------|-------------|
| Number of Stages â¬‡ï¸ | 4 | 6 |
| Training Epochs â±ï¸ | 2000 | 1000 |
| Learning Rate ğŸ“Š | 0.001 | 0.01 |
| Target Spacing ğŸ“ | 2, 2, 3 | 0.8, 0.8, 3 |

> ğŸ’¡ Our method achieves efficient segmentation with fewer stages and lower resample resolution.

## ğŸ“‚ Key Files in this Repository

Only two files you need to focus on:

1. [nnUNetTrainer_varianst.py](./nnunetv2/training/nnUNetTrainer/nnUNetTrainer_varianst.py)
   - Custom nnUNet trainer with modified training parameters
   
2. [plans.json](./nnUNet_results/Dataset024_FLARE24_Task1/nnUNetTrainer_Epoch2000_Lr1e3__nnUNetPlans__3d_fullres_S4D2W32/plans.json) 
   - Network architecture and configuration settings

## How to Reimplement?

### ğŸ› ï¸ Environment Setup
First, ensure you have **PyTorch > 2.0** installed with CUDA support. We conducted our experiments using **nnUNet v2.2**, which might slightly differ from the latest version **nnUNet v2.4**.
Set up your environment by running:
```bash
conda create -n FLARE24_gmai
conda activate FLARE24_gmai
pip install -e .
```

### ğŸ“‚ Data Preparation

- **ğŸ“ Dataset**: FLARE24 Task1
- **ğŸ”¢ Data Usage**: 5000 partial labeled data (treated as fully labeled without any special handling)
- **âš™ï¸ Preprocessing**: Default nnUNet procedure

Organize your labeled data in ``nnUNet_raw`` in the following structure:
```
Dataset024_FLARE24_Task1/
â”œâ”€â”€ imagesTr/
â”‚   â”œâ”€â”€ coronacases_001_0000.nii.gz
â”‚   â”œâ”€â”€ ...
â”‚   â””â”€â”€ (all 5,000 labeled images ending with .nii.gz)
â”œâ”€â”€ labelsTr/
â”‚   â”œâ”€â”€ coronacases_001.nii.gz
â”‚   â”œâ”€â”€ ...
â””â”€â”€ dataset.json
```
You can find the [dataset.json](./nnUNet_results/Dataset024_FLARE24_Task1/nnUNetTrainer_Epoch2000_Lr1e3__nnUNetPlans__3d_fullres_S4D2W32/dataset.json) file here

### ğŸ“ Data Preprocessing
#### 1. ğŸ§¬ Extract Fingerprints and Plan the Experiment:
```bash
nnUNetv2_extract_fingerprint -d 24
nnUNetv2_plan_experiment -d 24
```
#### 2. ğŸ› ï¸ Modify the Plans:
Edit the ``plans file`` in your ``nnUNet_preprocessed`` directory. Refer to our [plans.json](./nnUNet_results/Dataset024_FLARE24_Task1/nnUNetTrainer_Epoch2000_Lr1e3__nnUNetPlans__3d_fullres_S4D2W32/plans.json) for guidance. We modified the "patch_size" and "spacing" under "3d_fullres" and create a new configuration "3d_fullres_S4D2W32".
#### 3. âš™ï¸ Preprocess the Data:
```bash
nnUNetv2_preprocess -d 24 -c 3d_fullres -np 4
```

### ğŸš€ Training and Inference
#### ğŸ”§ Training the Model:
Train the network using the following command:
```bash
nnUNetv2_train 24 3d_fullres_S4D2W32 all -tr nnUNetTrainer_Epoch2000_Lr1e3
```
Alternatively, you can use our pre-trained model by copying it into your nnUNet_results folder. You can find our trained model [here](./nnUNet_results/Dataset024_FLARE24_Task1) 
#### ğŸ” Inference:
To perform inference, run:
```
nnUNetv2_predict -i ./inputs -o ./outputs -c 3d_fullres_S4D2W32 -f all -d 24 -tr nnUNetTrainer_Epoch2000_Lr1e3
```

## Results

### ğŸ“Š Quantitative Results

| Methods | Public Validation |  | Online Validation |  | Testing |  |
|---------|------------------|--|------------------|--|---------|--|
|         | DSC(%) | NSD(%) | DSC(%) | NSD(%) | DSC(%) | NSD(%) |
| Ours    | 25.34 Â± 31.56 | 24.40 Â± 27.80 | - | - | - | - |

### ğŸ–¼ï¸ Visualization

<img src="imgs/flare23-results.png" width="600"/>

*Two examples with good segmentation results and two examples with bad segmentation results in the validation set.*